TRAIN:

    exp_name: "test_sp_4"
    train_seed: 12345  # seed for training; will be generated and saved automatically if set to None
    num_epochs: 432  # total number of epochs
    perform_valid: False  # evaluate on valid set after every epoch
    use_tensorboard: True
    save: True  # save models
    save_period: 4  # use higher values to save less models. Make sure that it divides the number of epochs

    DATA:
        name: "cifar10"
        batch_size: 256

    OPTIMIZER:
        name: "TFRMSprop"
        lr: 0.2
        momentum: 0.9
        weight_decay: 0.0001
        eps: 1.0

    SCHEDULER:
        name: "cosine"
        T_max: 432

    CRITERION:
        name: "cross_entropy"

    GRAPH_SAMPLER:
        name: "GraphSampler101"
        dataset_path: "./datasets/sp_4.pkl"
        n_monte: 1  # number of architecture sampled in each batch
        prorata: False  # sample pro-rata to number of parameters
        n_nodes: 7

    GRAPH_MODEL:
        name: "GraphModel101"
        c_init: 16  # number of channels of the first convolution
        input_channels: 3
        single_k: False  # use single-path
        n_out_min: 4 # minimum number of nodes going to the output MAKE SURE THAT THIS VALUE IS CORRECT

        # conv layers parameters
        layers_params:
            conv_bias: False  # bias on conv layers
            bn_affine: True  # affine parameters on bn layers
            bn_momentum: 0.003  # momentum on bn layers. Careful: PyTorch and tensorflow conventions are different !
            bn_eps: 0.00001  # eps on bn layers

        # topology of the super-net
        n_cells: 3  # number of cells per stack
        n_stacks: 3  # number of stacks
        n_classes: 10
        n_nodes: 7

EVAL:

    eval_seed: 12345  # seed for evaluation; will be generated and saved automatically if set to None
    eval_all: False
    n_rand_evals: 1000  # number of models sampled and evaluated

    ft_bn_stats: True  # whether or not to ft only the bn stats before evaluating a model
    ft_weights: False  # whether or not to ft all the weights of the super-net to a specific model before evaluating

    n_ft_bn_stats: 4  # number of mini-batches to compute bn stats on
    n_ft_weights: 157  # number of weights ft steps 157 is one epoch


